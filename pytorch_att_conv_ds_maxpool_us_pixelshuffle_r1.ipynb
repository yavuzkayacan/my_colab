{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5SNo0FQRcB9ppsdzT7cc4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yavuzkayacan/my_colab/blob/main/pytorch_att_conv_ds_maxpool_us_pixelshuffle_r1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xqb81w5juDFn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import einsum\n",
        "from torch import Tensor\n",
        "import math\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageFile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "igGQ5qvwvS_E"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Patches(nn.Module):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "\n",
        "    def forward(self, images):\n",
        "        batch_size, channels, height, width = images.size()\n",
        "\n",
        "        patches = images.unfold(2, self.patch_size[0], self.patch_size[0]).unfold(3, self.patch_size[1], self.patch_size[1])\n",
        "        patches = patches.contiguous().view(batch_size, channels, -1, self.patch_size[0], self.patch_size[1])\n",
        "\n",
        "\n",
        "        return patches"
      ],
      "metadata": {
        "id": "f-TRyxfQvTlv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchComb(nn.Module):\n",
        "\n",
        "    def __init__(self, patch_size, num_patches, ch):\n",
        "        super(PatchComb, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = num_patches\n",
        "        self.ch = ch\n",
        "\n",
        "    def forward(self,patches):\n",
        "        reshaped_patches = torch.reshape(patches, (-1, self.num_patches[0], self.num_patches[1], self.patch_size[0], self.patch_size[1], self.ch))\n",
        "        reshaped_patches = reshaped_patches.permute(0, 5, 1, 3, 2, 4)\n",
        "        reshaped_patches = torch.reshape(reshaped_patches, (-1, self.ch, self.num_patches[0]*self.patch_size[0], self.num_patches[1]*self.patch_size[1]))\n",
        "        return reshaped_patches"
      ],
      "metadata": {
        "id": "4EAt7o6zvhvS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvAttention(nn.Module):\n",
        "    def __init__(self, n_channels):\n",
        "        super(ConvAttention, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.query = nn.Conv3d(self.n_channels, self.n_channels, kernel_size=3, padding='same')\n",
        "        self.key = nn.Conv3d(self.n_channels, self.n_channels, kernel_size=3, padding='same')\n",
        "        self.value = nn.Conv3d(self.n_channels, self.n_channels, kernel_size=3, padding='same')\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        size = x.shape\n",
        "        f, g, h = self.query(x), self.key(x), self.value(x)\n",
        "        mat_mul = torch.matmul(f.permute(0, 1, 2, 3, 4), g)\n",
        "        beta = F.softmax(mat_mul, dim=1)\n",
        "        o = self.gamma * torch.matmul(h, beta) + x\n",
        "\n",
        "        return mat_mul"
      ],
      "metadata": {
        "id": "M5lJjddbvj5P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand((1,16,256,64))"
      ],
      "metadata": {
        "id": "UFvI2ywGvnv4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (1, 256, 64)\n",
        "patch_size = [4, 4]\n",
        "num_patches = (input_shape[1] // patch_size[0]) * (input_shape[2] // patch_size[1])\n",
        "projection_dim = 64\n",
        "num_patch = np.array(((input_shape[1] // patch_size[0]) , (input_shape[2] // patch_size[1])))"
      ],
      "metadata": {
        "id": "xErCcUdwvvUp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ch_in = 1"
      ],
      "metadata": {
        "id": "iavT1TkPv9hN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = nn.Conv2d(X.shape[1], ch_in ,kernel_size=3, padding='same')(X)"
      ],
      "metadata": {
        "id": "LDOEKd4PvxyL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnPW2I9Mv6DH",
        "outputId": "45f51c05-a2bf-4f77-f717-3db6baca3329"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 256, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patch_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peC17ASu5ARN",
        "outputId": "ca0360c2-b7c5-4cc2-9928-0089fddf0854"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = Patches(patch_size)(X)"
      ],
      "metadata": {
        "id": "rdSUMbM3wAct"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXdIDPCRwDLp",
        "outputId": "c1a665b7-c5d9-4840-b244-15efc359208d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 1024, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = ConvAttention(ch_in)(X)"
      ],
      "metadata": {
        "id": "QbfFOn1EwEIT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27D1HIpNjxat",
        "outputId": "202fef34-8189-4f2d-de23-6bdb7862b6a7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 1024, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = PatchComb(patch_size, num_patch, ch_in)(X)"
      ],
      "metadata": {
        "id": "F31X0jedjvxd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDIW4a0-wHxB",
        "outputId": "97a1265d-b75b-4c09-88fc-29aef6b8a25f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 256, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.PixelUnshuffle(2)(X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kf3IYek9wJI5",
        "outputId": "0ca1ef59-9d8d-4440-d76a-0644a130db64"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 128, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv_Transformers(nn.Module):\n",
        "    def __init__(self, patch_size, num_patch, in_ch, ch, depth):\n",
        "        super(Conv_Transformers, self).__init__()\n",
        "\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patch = num_patch\n",
        "        self.in_ch = in_ch\n",
        "        self.ch = ch\n",
        "\n",
        "        self.depth = depth\n",
        "\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=self.in_ch, out_channels=self.ch, kernel_size=1,padding='same')\n",
        "\n",
        "        self.patching = Patches(self.patch_size)  # Assuming Patches is defined\n",
        "        self.conv_att = ConvAttention(self.ch)  # Assuming ConvAttention is defined\n",
        "        self.patch_comb = PatchComb(self.patch_size, self.num_patch, self.ch)  # Assuming PatchComb is defined\n",
        "\n",
        "        self.ds = nn.PixelUnshuffle(2)\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        X = self.conv(X)\n",
        "        X = self.patching(X)\n",
        "        X = self.conv_att(X)\n",
        "        X = self.patch_comb(X)\n",
        "        X = self.ds(X)\n",
        "\n",
        "\n",
        "        return X\n"
      ],
      "metadata": {
        "id": "BjbVRU5wzipr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_patch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KsyCfQm4B1s",
        "outputId": "c73d9b5c-cb46-48ef-ceb0-5e491467f9f1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([64, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8epJsivZ7VkD",
        "outputId": "826a4d24-e543-4b99-8588-5a9d04dee755"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 256, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Conv_Transformers(patch_size=patch_size,ch=64,in_ch=1,num_patch=num_patch,depth=1)(X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLsrSr4c2-J8",
        "outputId": "121c6a4b-9de4-4667-b3f2-5096a4e796f7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 256, 128, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv_Transformers(nn.Module):\n",
        "    def __init__(self, patch_size, num_patch, in_ch, ch, depth):\n",
        "        super(Conv_Transformers, self).__init__()\n",
        "\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patch = num_patch\n",
        "        self.in_ch = in_ch\n",
        "        self.ch = ch\n",
        "\n",
        "        self.depth = depth\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=self.in_ch, out_channels=self.ch, kernel_size=1,padding='same')\n",
        "        self.layers_down = nn.ModuleList()\n",
        "        self.layers_up = nn.ModuleList()\n",
        "        self.conv_out = nn.Conv2d(in_channels=self.ch*(self.depth+1), out_channels=1, kernel_size=1,padding='same')\n",
        "\n",
        "        self.down_ch = []\n",
        "\n",
        "        for _ in range(depth):\n",
        "\n",
        "\n",
        "          self.layers_down.append(nn.Sequential(\n",
        "          nn.Conv2d(in_channels=self.ch, out_channels=self.ch*4, kernel_size=1,padding='same'),\n",
        "          Patches(self.patch_size),  # Assuming Patches is defined\n",
        "          ConvAttention(self.ch*4),  # Assuming ConvAttention is defined\n",
        "          PatchComb(self.patch_size, self.num_patch, self.ch*4),  # Assuming PatchComb is defined\n",
        "          nn.MaxPool2d((2,2))\n",
        "          ))\n",
        "\n",
        "          #print(self.ch)\n",
        "\n",
        "          self.down_ch.append(self.ch)\n",
        "          self.ch = self.ch*4\n",
        "          self.num_patch =  self.num_patch // 2\n",
        "\n",
        "          #print(self.ch)\n",
        "\n",
        "\n",
        "        self.down_ch = self.down_ch[::-1]\n",
        "\n",
        "        for _ in range(depth):\n",
        "\n",
        "          self.layers_up.append(nn.Sequential(\n",
        "          Patches(self.patch_size),  # Assuming Patches is defined\n",
        "          ConvAttention(self.ch),  # Assuming ConvAttention is defined\n",
        "          PatchComb(self.patch_size, self.num_patch, self.ch),  # Assuming PatchComb is defined\n",
        "          nn.PixelShuffle(2)\n",
        "          ))\n",
        "          #print(self.ch//4 , self.down_ch[_])\n",
        "          self.ch = self.ch//4 + self.down_ch[_]\n",
        "\n",
        "          #print(self.ch)\n",
        "          self.num_patch =  self.num_patch * 2\n",
        "\n",
        "    def forward(self,X):\n",
        "        X_skip = []\n",
        "        X = self.conv(X)\n",
        "\n",
        "        for i in range(self.depth):\n",
        "            X_skip.append(X)\n",
        "            X = self.layers_down[i](X)\n",
        "\n",
        "            print(X.shape,X_skip[i].shape)\n",
        "\n",
        "        X_skip = X_skip[::-1]\n",
        "\n",
        "\n",
        "        for i in range(self.depth):\n",
        "\n",
        "            X = self.layers_up[i](X)\n",
        "            print(X.shape)\n",
        "            X_con = torch.cat([X,X_skip[i]],1)\n",
        "            X = X_con\n",
        "            print(X.shape)\n",
        "\n",
        "        out = self.conv_out(X)\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "sSQNbyx03PdC"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand((1,1,256,64))"
      ],
      "metadata": {
        "id": "D6lnEVX88fRt"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_s = Conv_Transformers(patch_size=patch_size,ch=16,in_ch=1,num_patch=num_patch,depth=3)(X)"
      ],
      "metadata": {
        "id": "mDn4ztjm85lz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0928b0a9-508f-4765-9b68-a3dbf1b260ee"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 64, 128, 32]) torch.Size([1, 16, 256, 64])\n",
            "torch.Size([1, 256, 64, 16]) torch.Size([1, 64, 128, 32])\n",
            "torch.Size([1, 1024, 32, 8]) torch.Size([1, 256, 64, 16])\n",
            "torch.Size([1, 256, 64, 16])\n",
            "torch.Size([1, 512, 64, 16])\n",
            "torch.Size([1, 128, 128, 32])\n",
            "torch.Size([1, 192, 128, 32])\n",
            "torch.Size([1, 48, 256, 64])\n",
            "torch.Size([1, 64, 256, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_s.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPQnbp3c8nxP",
        "outputId": "841011a4-c424-4c65-b309-d89893c998f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 256, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Conv_Transformers(patch_size=patch_size,ch=16,in_ch=1,num_patch=num_patch,depth=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1XL5rLB7tzL",
        "outputId": "875f24fd-d07d-4327-c4b7-694ccd420a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv_Transformers(\n",
              "  (conv): Conv2d(1, 16, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
              "  (layers_down): ModuleList(\n",
              "    (0): Sequential(\n",
              "      (0): Patches()\n",
              "      (1): ConvAttention(\n",
              "        (query): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
              "        (key): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
              "        (value): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
              "      )\n",
              "      (2): PatchComb()\n",
              "      (3): PixelUnshuffle(downscale_factor=2)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Patches()\n",
              "      (1): ConvAttention(\n",
              "        (query): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
              "        (key): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
              "        (value): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
              "      )\n",
              "      (2): PatchComb()\n",
              "      (3): PixelUnshuffle(downscale_factor=2)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): Patches()\n",
              "      (1): ConvAttention(\n",
              "        (query): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
              "        (key): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
              "        (value): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
              "      )\n",
              "      (2): PatchComb()\n",
              "      (3): PixelUnshuffle(downscale_factor=2)\n",
              "    )\n",
              "  )\n",
              "  (layers_up): ModuleList(\n",
              "    (0): Sequential(\n",
              "      (0): Patches()\n",
              "      (1): ConvAttention(\n",
              "        (query): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
              "        (key): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
              "        (value): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
              "      )\n",
              "      (2): PatchComb()\n",
              "      (3): PixelShuffle(upscale_factor=2)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Patches()\n",
              "      (1): ConvAttention(\n",
              "        (query): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
              "        (key): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
              "        (value): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
              "      )\n",
              "      (2): PatchComb()\n",
              "      (3): PixelShuffle(upscale_factor=2)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): Patches()\n",
              "      (1): ConvAttention(\n",
              "        (query): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
              "        (key): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
              "        (value): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
              "      )\n",
              "      (2): PatchComb()\n",
              "      (3): PixelShuffle(upscale_factor=2)\n",
              "    )\n",
              "  )\n",
              "  (conv_out): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_s.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orL7oBZ46_eZ",
        "outputId": "77cab4a3-f987-4baa-a05b-6d0304b529a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 256, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_s[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cafb641z8-VP",
        "outputId": "d7944585-76dc-49db-ec51-9c10e72ea02f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 256, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_s[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZ-u0AvyPgbc",
        "outputId": "3ea482c1-6cc0-4bcc-9d55-e167321635b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 128, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_s[2].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ee9V5IHPjfb",
        "outputId": "ef6b21ff-cf45-47e5-8c68-f98c898e4360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 256, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EoYQRlk5PmQu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}